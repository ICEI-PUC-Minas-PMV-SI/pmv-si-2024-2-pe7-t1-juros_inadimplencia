# Prepara√ß√£o dos dados

Nesta etapa, dever√£o ser descritas todas as t√©cnicas utilizadas para pr√©-processamento/tratamento dos dados. As informa√ß√µes de tratamento de dados aqui descritas foram utilizadas para o tratamento dos dados que foram utilizados para todos os modelos apresentados, para que fosse poss√≠vel comparar os resultados dos modelos, sem que houvesse influ√™ncia da base de dados.

Algumas das etapas podem estar relacionadas √†:

* Limpeza de Dados: trate valores ausentes: decida como lidar com dados faltantes, seja removendo linhas, preenchendo com m√©dias, medianas ou usando m√©todos mais avan√ßados; remova _outliers_: identifique e trate valores que se desviam significativamente da maioria dos dados.

* Transforma√ß√£o de Dados: normalize/padronize: torne os dados compar√°veis, normalizando ou padronizando os valores para uma escala espec√≠fica; codifique vari√°veis categ√≥ricas: converta vari√°veis categ√≥ricas em uma forma num√©rica, usando t√©cnicas como _one-hot encoding_.

* _Feature Engineering_: crie novos atributos que possam ser mais informativos para o modelo; selecione caracter√≠sticas relevantes e descarte as menos importantes.

* Tratamento de dados desbalanceados: se as classes de interesse forem desbalanceadas, considere t√©cnicas como _oversampling_, _undersampling_ ou o uso de algoritmos que lidam naturalmente com desbalanceamento.

* Separa√ß√£o de dados: divida os dados em conjuntos de treinamento, valida√ß√£o e teste para avaliar o desempenho do modelo de maneira adequada.
  
* Manuseio de Dados Temporais: se lidar com dados temporais, considere a ordena√ß√£o adequada e t√©cnicas espec√≠ficas para esse tipo de dado.
  
* Redu√ß√£o de Dimensionalidade: aplique t√©cnicas como PCA (An√°lise de Componentes Principais) se a dimensionalidade dos dados for muito alta.

* Valida√ß√£o Cruzada: utilize valida√ß√£o cruzada para avaliar o desempenho do modelo de forma mais robusta.

* Monitoramento Cont√≠nuo: atualize e adapte o pr√©-processamento conforme necess√°rio ao longo do tempo, especialmente se os dados ou as condi√ß√µes do problema mudarem.

* Entre outras....

Avalie quais etapas s√£o importantes para o contexto dos dados que voc√™ est√° trabalhando, pois a qualidade dos dados e a efic√°cia do pr√©-processamento desempenham um papel fundamental no sucesso de modelo(s) de aprendizado de m√°quina. √â importante entender o contexto do problema e ajustar as etapas de prepara√ß√£o de dados de acordo com as necessidades espec√≠ficas de cada projeto.



## Prepara√ß√£o dos dados

Quanto √† limpeza dos dados e remo√ß√£o de outliers, as bases selecionadas n√£o apresentavam dados faltantes nem a necessidade de remo√ß√£o de outliers.
J√° na Transforma√ß√£o de Dados, foi verificado a escala das vari√°veis, especialmente para a Regress√£o Linear, pois os algoritmos de aprendizado se beneficiam de dados em
uma mesma escala. Decidimos manter as vari√°veis na escala original devido ao uso de Random Forest, tendo qme vista que este modelo n√£o √© sens√≠vel a escalas, e yamb√©m para permitir uma interpreta√ß√£o direta 
dos coeficientes na Regress√£o Linear. A coluna Per√≠odo, que representa o tempo, foi convertida para o tipo datetime para garantir a manipula√ß√£o e ordena√ß√£o corretas dos 
dados, uma vez que ela representa uma vari√°vel temporal importante para o modelo.

No Manuseio de Dados Temporais, foi essencial ordenar a coluna Per√≠odo em ordem 
crescente para manter a sequ√™ncia temporal em visualiza√ß√£o, possbilitando uma an√°lise consistente ao longo do tempo. Essa ordena√ß√£o permite observar melhor as tend√™ncias e rela√ß√µes 
ao longo dos per√≠odos. Quanto √† Separa√ß√£o de Dados, dividimos os dados em conjuntos de treino e teste usando uma propor√ß√£o de 70/30 para uma avalia√ß√£o confi√°vel do modelo. 
O conjunto de treino foi utilizado para ajustar os modelos, enquanto o conjunto de teste ajudou a avaliar a performance dos mesmos em dados n√£o vistos. Essas etapas de 
prepara√ß√£o de dados foram fundamentais para garantir que os modelos tivessem uma base confi√°vel e representativa dos dados reais, aumentando a precis√£o e a generaliza√ß√£o
dos modelos de predi√ß√£o. Na prepara√ß√£o dos dados buscamos assegurar que o aprendizado dos algoritmos capturasse padr√µes importantes, maximizando o desempenho e a validade das 
previs√µes feitas para o endividamento das fam√≠lias.

![IMG 1](https://github.com/user-attachments/assets/cf9f418b-ec28-4473-a875-01738e19df1a)

Base utilizada para Regress√£o Linear, Random Forest e Prophet.(Arquivo presente na pasta SRC)

# Descri√ß√£o dos modelos

Nesta se√ß√£o, conhecendo os dados e a maneira que foram preparados, vamos descrever os algoritmos de aprendizado de m√°quina selecionados para a constru√ß√£o dos modelos propostos. Inclua informa√ß√µes abrangentes sobre cada algoritmo implementado, aborde conceitos fundamentais, princ√≠pios de funcionamento, vantagens/limita√ß√µes e justifique a escolha de cada um dos algoritmos. 

Explore aspectos espec√≠ficos, como o ajuste dos par√¢metros livres de cada algoritmo. Lembre-se de experimentar par√¢metros diferentes e principalmente, de justificar as escolhas realizadas.

Como parte da comprova√ß√£o de constru√ß√£o dos modelos, um v√≠deo de demonstra√ß√£o com todas as etapas de pr√©-processamento e de execu√ß√£o dos modelos dever√° ser entregue. Este v√≠deo poder√° ser do tipo _screencast_ e √© imprescind√≠vel a narra√ß√£o contemplando a demonstra√ß√£o de todas as etapas realizadas.

## Descri√ß√£o dos modelos


Os modelos de predi√ß√£o cujos algoritmos baseados em aprendizado de m√°quina escolhidos foram: Regress√£o Linear, Random Forest e an√°lise de s√©ries temporais (Prophet). 
Os algoritmos foram selecionados devido √†s suas caracter√≠sticas distintas e aos benef√≠cios que ofereciam para entender e prever o comportamento dos dados em rela√ß√£o ao endividamento das fam√≠lias.

Em cada modelo, foram testados diferentes configura√ß√µes de par√¢metros. Na Regress√£o Linear decidimos utilizar uma abordagem direta, sem regulariza√ß√£o adicional. 
No caso do Random Forest, experimentamos valores crescentes de n_estimators e diferentes profundidades m√°ximas para garantir um equil√≠brio entre precis√£o e performance. J√° no Prophet, optamos por adicionar diferentes regressores (que se tratam de diversos √≠ndices macroecon√¥micos) para estimarmos a varia√ß√£o do endividamento das fam√≠lias no decorrer do tempo.
Essas escolhas se justificam pela observa√ß√£o dos erros e pela variabilidade dos dados.

# Experimento #1

## Regress√£o Linear Simples
A an√°lise realizada utilizou regress√£o linear simples para explorar a rela√ß√£o entre o percentual de endividamento das fam√≠lias baseado no Sistema Financeiro Nacional (SFN) e as vari√°veis "Selic_Valor", "Confian√ßa_Valor" e "Inflacao_Acumulada". O objetivo era investigar como a varia√ß√£o da taxa Selic influencia o endividamento, considerando tamb√©m o impacto da infla√ß√£o e do √≠ndice de confian√ßa do consumidor.

Para construir os modelos, foi utilizada a biblioteca `sklearn` para dividir os dados em conjuntos de treino e teste e ajustar um modelo linear. O trecho do c√≥digo abaixo exemplifica o processo:

```python
#separar os dados das vari√°veis, dependente e independente
x = dados[['Selic_Valor']] #vari√°vel dependente (Selic)
y = dados[['Endividamento_SFN']] #vari√°vel independente (Endividamento)

#dividir dados para treinamento e teste
from sklearn.model_selection import train_test_split
x_treino, x_teste, y_treino, y_teste, data_treino, data_teste = train_test_split(x, y, data, test_size = 0.2, random_state = 42)

#criar o modelo de Regress√£o LInear Simples e Treinar o modelo
from sklearn import linear_model
modelo = linear_model.LinearRegression()
modelo.fit(x_treino, y_treino)

#m√©tricas do Modelo
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
print(mean_absolute_error(y_teste, y_pred))
print(mean_squared_error(y_teste, y_pred))
print(r2_score(y_teste, y_pred))

#coeficiente (inclina√ß√£o da reta)
coeficiente = modelo.coef_[0]
print(coeficiente)
```
### Endividamento vs Selic

```
Mean Absolute Error 2.513171289925124
Mean Squared Error: 8.717099884190315
R2-Score: -0.049468720426556034
Coeficiente: [0.12235752]
```

Os resultados para a vari√°vel "Selic_Valor" mostraram que o coeficiente da regress√£o foi 0,1224, indicando que, em m√©dia, um aumento de 1 ponto percentual na taxa Selic est√° associado a um aumento de 0,1224% no endividamento SFN. No entanto, o valor de R¬≤ foi -0,049, sugerindo que a Selic, sozinha, n√£o explica a varia√ß√£o no endividamento.

> [!NOTE]
> Para ver o c√≥digo deste modelo clique no link üëâ [endividamento_selic.py](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/src/endividamento_selic_alisson_bruno.py).

<div align="center">
  
![Endividamento vs Selic - Regress√£o Linear Simples](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/docs/img/endividamento_selic.png)

</div>

### Endividamento vs √çndice de Confian√ßa do COnsumidor
```
Mean Absolute Error 1.9215478332539357
Mean Squared Error: 7.593682007823295
R2-Score: 0.08578175701187307
Coeficiente: [0.05027029]
```
Para "Confian√ßa_Valor", o coeficiente foi 0,0503, indicando que um aumento de 1 ponto no √≠ndice de confian√ßa est√° associado a um aumento m√©dio de 0,0503% no endividamento SFN. O R¬≤ foi 0,086, mostrando uma explica√ß√£o um pouco melhor que a Selic, mas ainda muito limitada.

> [!NOTE]
> Para ver o c√≥digo deste modelo clique no link üëâ [endividamento_confianca.py](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/src/endividamento_confianca_alisson_bruno.py).

<div align="center">

![Endividamento vs ICC - Regress√£o Linear Simples](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/docs/img/endividamento_confianca.png)

</div>

### Endividamento vs Infla√ß√£o Acumulada
```
Mean Absolute Error 2.475296029909461
Mean Squared Error: 9.044113375438034
R2-Score: -0.0888385148285209
Coeficiente: [0.36940184]
```
Por √∫ltimo, "Inflacao_Acumulada" apresentou um coeficiente de 0,3694, sugerindo que cada aumento de 1% na infla√ß√£o acumulada est√° associado a um aumento m√©dio de 0,3694% no endividamento SFN. No entanto, o valor de R¬≤ foi -0,088, refor√ßando que a infla√ß√£o, sozinha, tamb√©m n√£o √© um bom preditor do endividamento.

> [!NOTE]
> Para ver o c√≥digo deste modelo clique no link üëâ [endividamento_inflacao.py](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/src/endividamento_selic_alisson_bruno.py).

<div align="center">

![Endividamento vs Infla√ß√£o - Regress√£o Linear Simples](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/docs/img/endividamento_inflacao.png)

</div>


### Conclus√£o do experimento
Em s√≠ntese, os modelos indicam que as vari√°veis analisadas possuem rela√ß√µes positivas, por√©m muito fracas, com o n√≠vel de endividamento conforme medido pelo SFN. Valores baixos ou negativos de R¬≤ indicam que as vari√°veis isoladamente n√£o explicam bem o comportamento do endividamento. Isso sugere que outros fatores, como renda familiar, disponibilidade de cr√©dito e condi√ß√µes macroecon√¥micas, devem ser considerados.

Portanto, embora a an√°lise mostre uma influ√™ncia limitada da Selic no endividamento, a resposta √† quest√£o da pesquisa requer um modelo mais robusto que inclua m√∫ltiplas vari√°veis simultaneamente. Isso permitir√° entender melhor a rela√ß√£o entre a taxa Selic, a infla√ß√£o e o endividamento das fam√≠lias.

# Experimento #2

# Regress√£o Linear

A regress√£o linear √© um m√©todo estat√≠stico usado para modelar a rela√ß√£o entre uma vari√°vel dependente e uma ou mais vari√°veis independentes. O objetivo √© ajustar uma linha reta que minimiza a soma dos quadrados das diferen√ßas entre os valores observados e os valores previstos. Tamb√©m foi observado que ele possui apenas o par√¢metro de coeficiente de inclina√ß√£o da linha.

![image](https://github.com/user-attachments/assets/d762a977-3d38-40d7-be28-f27a600876ad)
![image](https://github.com/user-attachments/assets/3af2fc80-efa0-440e-820a-d0238bb04457)

A Regress√£o Linear foi escolhida devido √† sua capacidade de fornecer uma linha de base para compara√ß√£o com outros modelos mais complexos. 
Ela ajuda a identificar se uma simples rela√ß√£o linear √© suficiente para explicar os dados. Neste primeiro teste, optamos por uma Regress√£o Linear simples como
ponto de partida.

![RegressaoLinear](https://github.com/user-attachments/assets/57316d07-b0ec-479f-b299-f45c6494c935)

> [!NOTE]
> Para ver o c√≥digo deste modelo clique no link üëâ [Regressao_Linear_LucasLima_Geraldo .py](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/src/Regressao_Linear_LucasLima_Geraldo%20.py).



# Random Forest

O Random Forest √© um algoritmo de aprendizado de m√°quina baseado em conjuntos que constr√≥i m√∫ltiplas √°rvores de decis√£o durante o treinamento e apresenta a m√©dia das previs√µes individuais das √°rvores para melhorar a precis√£o. Uma das vantagens √© sua robustez em rela√ß√£o a outliers e sua capacidade de lidar bem com grandes conjuntos de dados por outro lado, pode ser complicado ter poder computacional suficiente para processar os dados e sua interpreta√ß√£o pode ser mais complicada.
Com os par√¢metros livres alteramos os:

![image](https://github.com/user-attachments/assets/d01f3556-fe05-4b41-86d1-c23e914963ec)

n_estimators. Que √© o n√∫mero de √°rvores na floresta.

max_depth. que √© a profundidade m√°xima de cada √°rvore.

min_samples_split que √© o n√∫mero m√≠nimo de amostras necess√°rias para dividir um n√≥ interno.

![image](https://github.com/user-attachments/assets/556c1605-8574-4416-8ab9-a434e6afef35)


A escolha do Random Forest como um modelo foi para analisar rela√ß√µes n√£o-lineares entre as vari√°veis independentes, al√©m de experimentarmos diferentes valores para n_estimators e max_depth para encontrar o melhor ajuste, buscando tentar prever o n√≠vel de endividamento.

![RandomForest](https://github.com/user-attachments/assets/fce3e796-4927-409c-b3c0-b939d73017cf)

> [!NOTE]
> Para ver o c√≥digo deste modelo clique no link üëâ [Random_Forest_LucasLima_Geraldo.py](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/src/Random_Forest_LucasLima_Geraldo.py).

## Avalia√ß√£o dos modelos criados

A decis√£o em compilar os itens solicitados na parte da avalia√ß√£o dos modelos foram: Come√ßando pelas m√©tricas onde foi usado a Mean Squared Error a MSE. Ela mede a m√©dia dos quadrados dos erros, que s√£o as diferen√ßas entre os valores previstos e os valores observados. Foi decidido a escolha do MSE, pois √© uma m√©trica comum para problemas de regress√£o e √© f√°cil de interpretar e tamb√©m do R^2 Score. Ele representa a propor√ß√£o da vari√¢ncia da vari√°vel dependente que √© explicada pelas vari√°veis independentes no modelo. O R^2 tamb√©m foi escolhido pois ele fornece uma medida de qu√£o bem os valores previstos se ajustam aos dados reais.

Sobre os resultados obtidos: a Regress√£o Linear forneceu uma linha de base simples, mas completa para a an√°lise dos dados. A MSE foi de de 13.91 indica que a m√©dia dos erros ao quadrado das previs√µes do modelo foi relativamente alta, mostrando que as previs√µes n√£o estavam muito pr√≥ximas dos valores reais. Al√©m disso, o R^2 Score negativo de -0.06 nos diz que o modelo n√£o foi capaz de capturar a varia√ß√£o nos dados de forma eficaz, o que significa que as previs√µes feitas pela regress√£o linear s√£o menos confi√°veis. Isto pode ser atribu√≠do √† simplicidade do modelo, que assume uma rela√ß√£o linear entre as vari√°veis, n√£o capturando as complexidades e n√£o linearidades presentes nos dados .

![image](https://github.com/user-attachments/assets/4f55d4fe-1134-407f-b425-fa1418bbaed4)


Na compara√ß√£o entre os modelos de Random Forest e Regress√£o Linear, conclui-se que o primeiro apresentou MSE de 7.07, menor do que a da Regress√£o Linear, ou seja, o modelo de Random Forest fez previs√µes mais pr√≥ximas dos valores reais. No entanto, o R^2 Score de -0.22 sugere que a Regress√£o Linear tenha sido mais eficiente em explicar as varia√ß√µes dos dados. 

![image](https://github.com/user-attachments/assets/369cb0c0-dca6-4a96-9765-ad3327742d1f)


Ambos os modelos mostram a necessidade de uma an√°lise mais profunda e possivelmente a integra√ß√£o de dos e metodos adicionais para demostrar melhor as varia√ß√µes nos dados de endividamento familiar. A Regress√£o Linear, apesar de ser uma boa linha de base, n√£o √© suficiente para este conjunto de dados, enquanto o Random Forest, mesmo sendo mais eficaz, ainda precisa ser ajustado para um desempenho superior.

Estas an√°lises e interpreta√ß√µes apesar de n√£o retornarem o resultado desejado foram essenciais para entendermos as limita√ß√µes dos modelos e dados utilizados e apontam para futuras melhorias e ajustes, visando previs√µes mais precisas e confi√°veis.

# Experimento #3

# Prophet

A an√°lise de s√©ries temporais √© um m√©todo de estudar como uma vari√°vel muda ao longo do tempo, ajudando a identificar padr√µes, tend√™ncias, ciclos, sazonalidade e outliers em seus dados. Esse m√©todo tamb√©m √© utilizado para prever valores futuros de sua vari√°vel com base em dados hist√≥ricos. 

Essa t√©cnica se diferencia da an√°lise de regress√£o em tr√™s pontos: 1) enquanto as s√©ries temporais se concentram em como uma √∫nica vari√°vel muda ao longo do tempo, a regress√£o se concentra em como m√∫ltiplas vari√°veis interagem entre si; 2) an√°lise de s√©ries temporais presume que os dados s√£o dependentes no tempo e t√™m autocorrela√ß√£o, enquanto a an√°lise de regress√£o assume que os dados s√£o independentes e n√£o t√™m multicolinearidade; 3) por fim, enquanto, os dados de s√©ries temporais s√£o organizados em ordem cronol√≥gica, os dados de regress√£o n√£o s√£o necessariamente ordenados. (SAMMARRAIE, 2024).

O Prophet √© um algoritmo desenvolvido pelo Facebook que trabalha com previs√£o de s√©ries temporais. √â baseado em um modelo aditivo em que tend√™ncias n√£o-lineares s√£o ajustadas com sazonalidade mensal, di√°ria e anual, al√©m dos efeitos dos feriados. (FACEBOOK, 2023). 

Visando um maior entendimento do funcionamento do algoritmo do Prophet, optamos por gerar dois modelos: um em que o Prophet utiliziaria apenas a varia√ß√£o do n√≠vel de endividamento no per√≠odo entre mar√ßo de 2011 e maio de 2024 para gerar a previs√£o desse √≠ndice at√© 2030; e outro em que s√£o adicionados os regressores (varia√ß√£o do juros medidos pela Selic, o n√≠vel de confian√ßa e a infla√ß√£o mensal medida pelo IPCA) como vari√°veis externas que influenciam no comportamento do n√≠vel de endividamento.

Como se v√™ abaixo, os resultados gerados foram discrepantes na previs√£o at√© o ano de 2030: enquanto o modelo em que o Prophet usa apenas a varia√ß√£o do endividamento para previs√£o conclui que o n√≠vel de endividamento vai seguir uma tend√™ncia de crescimento at√© chegar 54% da popula√ß√£o em 2030, o modelo que utiliza os regressores estima que o n√≠vel de endividamento chegou a uma m√°xima em 2021 e deve seguir em queda at√© chegar em 42,5% no final do per√≠odo.


![image](https://github.com/user-attachments/assets/69821874-a52c-4e46-a299-381dd93244eb)



![image](https://github.com/user-attachments/assets/b584ca58-5e80-43bb-96da-7f8cc24169d7)

# Implementa√ß√£o dos modelos

A implementa√ß√£o do modelo foi feita atrav√©s dos seguintes passos:
1.	A instala√ß√£o da biblioteca Prophet.
2.	A separa√ß√£o das colunas de dados (j√° anteriormente parametrizadas) entre a coluna ds (as s√©ries de dados , que no caso seriam as datas separadas no modelo europeu, ou seja, aaaa-mm-dd) e a coluna y (que contem a vari√°vel dependente).
3.	O treinamento e configura√ß√£o do modelo: as etapas de treinamento e teste dos dados j√° est√£o embutidas na implementa√ß√£o do algoritmo Prophet no c√≥digo.
4.	4.	A utiliza√ß√£o do modelo para fazer previs√µes: usamos o ano de 2030 como ponto final das previs√µes do modelo, sendo poss√≠vel estimar a varia√ß√£o do endividamento de 2024 at√© l√°.
5.	A visualiza√ß√£o dos resultados atrav√©s da plotagem de gr√°ficos: os gr√°ficos trazem algumas fun√ß√µes que auxiliam a entender os impactos da incorpora√ß√£o de regressores no modelo.
6.	Avalia√ß√£o do modelo: c√°lculo do R¬≤ e do MSE.

Na implementa√ß√£o do modelo com regressores, adicionamos a fun√ß√£o abaixo, em que cada coluna contida em y1, y2 e y3 trazia os dados da taxa Selic, de Confian√ßa e da infla√ß√£o mensal, respectivamente.

for regressor in ['y1', 'y2', 'y3']:
    if regressor in tabela.columns:
        model.add_regressor(regressor)



> [!NOTE]
> Para ver o c√≥digo deste modelo clique no link üëâ [Prophet_LucasSantos_Vinicius.py](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/src/Prophet_LucasSantos_Vinicius.py).

# Avalia√ß√£o dos modelos criados

Para avaliar os modelos de s√©ries temporais usando o Prophet, a avalia√ß√£o foi feita atrav√©s do Erro Quadr√°tico M√©dio (MSE em ingl√™s) e do coeficiente de determina√ß√£o (R¬≤). Em primeiro lugar, os resultados da avalia√ß√£o do modelo em que foram inseridos os regressores ao modelo: enquanto o MSE apresentou um resultado moderado no desempenho do modelo (0.6242514687584728), na avalia√ß√£o atrav√©s do R¬≤ os resultados obtidos foram mais satisfat√≥rios (0.9593074801682949), indicando que o modelo explica quase totalmente a variabilidade dos dados.
J√° no modelo em que o Prophet usou apenas a varia√ß√£o do endividamento para prever a s√©rie temporal, os resultados tiveram resultados piores, indicando que o modelo anterior captou melhor os ajustes de cada vari√°vel. Enquanto o MSE apresentou 2.2756528607697546, √≠ndice acima acima do 1, ou seja, os erros foram elevados ao quadrado individualmente, indicando um resultado ruim para explicar a variabilidade dos dados finais. Al√©m disso, o R¬≤ tamb√©m apresentou um resultado pior que no outro modelo (0.8516590608090697), mesmo que ainda satisfat√≥rio por estar pr√≥ximo do 1.


# Experimento #4

# Modelo Sarima 

O modelo SARIMA (Seasonal AutoRegressive Integrated Moving Average) √© um modelo derivado do modelo ARIMA, que s√£o t√©cnicas que √™m como objetivos a an√°lise e a previs√£o de dados em s√©ries temporais. Este √© um modelo utilizado em an√°lises econ√¥micas, pois seu diferencial √© justamente a previs√£o das s√©ries temporais em conjuntos de dados. 

A implanta√ß√£o do modelo requer alguns passos, e os mais importantes ser√£o detalhados a seguir:

## Carregamento e tratamento dos dados

As bibliotecas Python importadas para execu√ß√£o de todos os passos:
````
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
````
Ap√≥s o carregamento dos dados, alguns cuidados devem ser tomados, a fim de garantir que o modelo seja capaz de identificar as s√©ries temporais adequadamente. No trecho a seguir, definimos a coluna "Periodo" como o √≠ndice, e o seu formato de data, para delimita√ß√£o da sazonalidade a ser observada pelo modelo.
````
# Definir data como √≠ndice
dados['Periodo'] = pd.to_datetime(dados['Periodo'], format='%m/%d/%Y')
dados = dados.set_index('Periodo')
````
Tamb√©m foi necess√°rio realizar a remo√ß√£o de colunas, para que o modelo pudesse isolar os indicadores e executar a previs√£o adequadamente:
````
# Removendo colunas para facilitar o entendimento do modelo
dados_endiv = dados.drop(['Confianca_Valor', 'Selic_Valor', 'Inflacao_Acumulada'],axis=1)
````

## Delimitando os dados de treino e teste

Nesta etapa, delimitamos os dados que seriam utilizados para o aprendizado do modelo, daqueles que seriam utilizados para valida√ß√£o das predi√ß√µes, para avalia√ß√£o dos resultados entregues pelo modelo. Para este exerc√≠cio, dividimos a base 
````
# Defini√ß√£o do treinamento e testes do modelo
dados_treino = dados_endiv[dados_endiv.index < '2019-06-01']
dados_teste = dados_endiv[dados_endiv.index >= '2019-06-01']
````
√â importante tamb√©m que seja verificada a estacionariedade dos dados. Este trecho de c√≥digo faz este trabalho, salientando que o resultado dever√° ser menor que 0.05 para que o modelo funcione corretamente:
````
# Verificar estacionariedade (resultado precisa ser menor que 0.05)
result = adfuller(dados_endiv)
print("p-valor:", result[1])
````

## Aplicando o modelo
Este trecho de c√≥digo √© respons√°vel pela aplica√ß√£o do modelo Sarima no conjunto de dados. Vale ressaltar que os valores dentro das vari√°veis `order` e `seasonal_order` ser√£o respons√°veis pelos ajustes a serem realizados. Estas vari√°veis s√£o definidas de acordo com as seguintes orienta√ß√µes:
p: Ordem do componente autorregressivo (AR). 
d: Ordem da diferencia√ß√£o n√£o sazonal. 
q: Ordem do componente de m√©dias m√≥veis (MA). 
P: Ordem do componente autorregressivo sazonal (SAR). 
D: Ordem da diferencia√ß√£o sazonal. 
Q: Ordem do componente de m√©dias m√≥veis sazonais (SMA). 
m: Per√≠odo da sazonalidade (por exemplo, 12 para dados mensais com sazonalidade anual). 

````
modelo = SARIMAX(dados_treino, order=(0,1,6), seasonal_order=(0,1,10,12)) 
resultado = modelo.fit()
````
Para o modelo, utilizamos os seguintes valores:
- P = 0, D = 1, Q = 6: Sem padr√£o sazonal esperado

- p = 0: Captura um efeito de depend√™ncia autorregressiva b√°sica
- d = 1: Para tornar a s√©rie estacion√°ria, caso necess√°rio
- q = 10: Permite capturar flutua√ß√µes curtas com m√©dia m√≥vel
- s = 12: Mantido como padr√£o, caso sazonalidade residual seja detectada

## Predi√ß√£o do modelo
O modelo √© aplicado em dois momentos, o primeiro, para a previs√£o com base no treinamento executado pelo algoritmo e valida√ß√£o com base nos dados de testes:
````
# Predi√ß√µes do modelo
predicao_teste = resultado.predict(start=dados_teste.index[0], end=dados_teste.index[-1])
````
E o segundo momento, onde √© realizada uma previs√£o que vai al√©m dos dados disponibilizados para treinamento e testes:
````
# Previs√£o para o modelo
passos_futuros = 36 # Vari√°vel recebe a quantidade de meses que faremos a previs√£o dos indicadores futuros
previsao = resultado.get_forecast(steps=passos_futuros)
````

## Impress√£o dos resultados
Como resultado das predi√ß√µes, encontramos os seguintes resultados, j√° levados para um gr√°fico agrupando os dados de treino, teste, predi√ß√µes realizadas para valida√ß√£o e predi√ß√µes para per√≠odos futuros √† s√©rie de dados fornecida para o modelo:
![image](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/docs/img/Treinamento%20Selic_Sarima.png)

## Avalia√ß√£o do modelo

Avaliar um modelo de predi√ß√£o √© uma quest√£o complicada, uma vez que, principalmente em rela√ß√£o a indicadores econ√¥micos, existem in√∫meros fatores externos que podem influenciar em movimentos de alta ou baixa de tais n√∫meros.
O Prophet e o Sarima s√£o os modelos mais capazes de realizar tais predi√ß√µes, mas devemos nos atentar para o tratamento da base de dados antes de aplicar o modelo. √â preciso que os dados sejam organizados e que um √≠ndice de tempo seja definido, para que o modelo possa buscar por padr√µes de sazonalidade e realizar predi√ß√µes adequadamente.
Alguns fatores externos podem influenciar o resultado dos indicadores no mundo real, o que torna dif√≠cil de uma predi√ß√£o pr√≥xima da realidade. Como exemplo, o resultado apresentado no gr√°fico a seguir, em que fica demononstrado que o modelo n√£o foi capaz de se adaptar a uma situa√ß√£o inesperada com grande efeito sobre todo o cen√°rio, como foi a pandemia da Covid-19. 

![image](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/docs/img/Previs%C3%A3o%20Selic%2036m_Sarima.png)

Por isso, √© necess√°rio que o analista de dados use a ferramenta para realizar as predi√ß√µes, mas tamb√©m, utilize do conhecimento relacionado a √°rea estudada e analisada pela s√©rie de dados.

![image](https://github.com/ICEI-PUC-Minas-PMV-SI/pmv-si-2024-2-pe7-t1-juros_inadimplencia/blob/main/docs/img/Resultado%20Selic_Sarima.png)

# Avalia√ß√£o do modelos criados

## M√©tricas utilizadas

Nesta se√ß√£o, as m√©tricas utilizadas para avaliar os modelos desenvolvidos dever√£o ser apresentadas (p. ex.: acur√°cia, precis√£o, recall, F1-Score, MSE etc.). A escolha de cada m√©trica dever√° ser justificada, pois esta escolha √© essencial para avaliar de forma mais assertiva a qualidade do modelo constru√≠do. 

## Discuss√£o dos resultados obtidos

Nesta se√ß√£o, discuta os resultados obtidos pelos modelos constru√≠dos, no contexto pr√°tico em que os dados se inserem, promovendo uma compreens√£o abrangente e aprofundada da qualidade de cada um deles. Lembre-se de relacionar os resultados obtidos ao problema identificado, a quest√£o de pesquisa levantada e estabelecendo rela√ß√£o com os objetivos previamente propostos. 

# Pipeline de pesquisa e an√°lise de dados

Em pesquisa e experimenta√ß√£o em sistemas de informa√ß√£o, um pipeline de pesquisa e an√°lise de dados refere-se a um conjunto organizado de processos e etapas que um profissional segue para realizar a coleta, prepara√ß√£o, an√°lise e interpreta√ß√£o de dados durante a fase de pesquisa e desenvolvimento de modelos. Esse pipeline √© essencial para extrair _insights_ significativos, entender a natureza dos dados e, construir modelos de aprendizado de m√°quina eficazes. 

## Observa√ß√µes importantes

Todas as tarefas realizadas nesta etapa dever√£o ser registradas em formato de texto junto com suas explica√ß√µes de forma a apresentar  os c√≥digos desenvolvidos e tamb√©m, o c√≥digo dever√° ser inclu√≠do, na √≠ntegra, na pasta "src".

Al√©m disso, dever√° ser entregue um v√≠deo onde dever√£o ser descritas todas as etapas realizadas. O v√≠deo, que n√£o tem limite de tempo, dever√° ser apresentado por **todos os integrantes da equipe**, de forma que, cada integrante tenha oportunidade de apresentar o que desenvolveu e as  percep√ß√µes obtidas.


# Pipeline

Finalizando com a nossa pipeline, resolvemos fazer toda a seguencia de a√ß√µes que fizemos para concluir a pesquisa para ajudar quem pretende trabalhar com os dados macroecon√¥micos e aprendizado de m√°quina no futuro. 
Come√ßamos o trabalho reunindo os dados hist√≥ricos sobre o valor da Selic, representada na base de dados como Selic_Valor, a infla√ß√£o acumulada, representada como Infla√ß√£o_Acumulada, e a confian√ßa do consumidor, representada como Confian√ßa_Valo. Al√©m disso, organizamos a s√©rie hist√≥rica do per√≠odo escolhido pegando os dados correspondentes ao dia primeiro de cada m√™s.

Prepara√ß√£o dos Dados: nessa etapa, realizamos a limpeza e formata√ß√£o, convertendo datas, alterando a v√≠rgula por ponto, separando e normalizando os dados selecionados. As vari√°veis foram mantidas na escala original para facilitar a interpreta√ß√£o direta, especialmente considerando o uso do Random Forest, que n√£o √© sens√≠vel a escalas.

Manuseio de Dados Temporais: A coluna Per√≠odo, que representa o tempo, foi convertida para o tipo datetime para garantir a manipula√ß√£o e ordena√ß√£o corretas dos dados. Ordenamos a coluna em ordem crescente para manter a sequ√™ncia temporal e garantir a visualiza√ß√£o e capacidade de an√°lise consistentes ao longo do tempo.

Separa√ß√£o dos Dados: Dividimos os dados em conjuntos de treino e teste na propor√ß√£o de 70/30 para uma avalia√ß√£o confi√°vel dos modelos. O conjunto de treino foi usado para ajustar os modelos, enquanto o conjunto de teste ajudou a avaliar a performance em dados n√£o vistos.

Constru√ß√£o do Modelo: Implementamos os algoritmos de Regress√£o Linear e Random Forest. Para a Regress√£o Linear, focamos em uma abordagem direta, sem regulariza√ß√£o adicional. No caso do Random Forest, experimentamos valores crescentes de n_estimators e diferentes profundidades m√°ximas (max_depth) para garantir um equil√≠brio entre precis√£o e performance. Os hiperpar√¢metros foram ajustados para otimizar o desempenho dos modelos.

Avalia√ß√£o do Modelo: Utilizamos m√©tricas como MSE (Mean Squared Error) e R^2 Score para avaliar o desempenho dos modelos. A Regress√£o Linear forneceu uma linha de base simples, mas completa para a an√°lise dos dados. A MSE foi de 13.91, indicando que a m√©dia dos erros ao quadrado das previs√µes do modelo foi relativamente alta. O R^2 Score negativo de -0.06 mostrou que o modelo n√£o capturou a varia√ß√£o nos dados de forma eficaz.

J√° no modelo de Random Forest, a MSE de 7.07 foi menor, indicando previs√µes mais pr√≥ximas dos valores reais. O R^2 Score de -0.22 ainda sugere que h√° margem para melhorias, mas o modelo foi mais eficaz em explicar as varia√ß√µes dos dados.

Nos modelos de s√©ries temporais baseado no algoritmo Prophet, a avalia√ß√£o tamb√©m se deu atrav√©s do Erro Quadr√°tico M√©dio (MSE em ingl√™s) e do coeficiente de determina√ß√£o (R¬≤). Em primeiro lugar, os resultados da avalia√ß√£o do modelo em que foram inseridos os regressores ao modelo: enquanto o MSE apresentou um resultado modesto no desempenho do modelo (0.6242514687584728, longe do 0, que indica que o desemepnho n√£o foi satisfat√≥rio), na avalia√ß√£o atrav√©s do R¬≤ os resultados obtidos foram bem-sucedidos (0.96, pr√≥ximo ao 1), indicando que o modelo explica quase totalmente a variabilidade dos dados.
J√° no modelo em que o Prophet usou apenas a varia√ß√£o do endividamento para prever a s√©rie temporal, tanto MSE quanto R¬≤ indicaram resultados piores do que no outro modelo, indicando que a adi√ß√£o de regressores para treinamento do modelo pode servir como subs√≠dio para melhor entendimento da varia√ß√£o do endividamento das fam√≠lias no Brasil.

Criamos gr√°ficos para comparar dados reais e previstos, a fim de tentar prever o endividamento das fam√≠lias. Esses gr√°ficos ajudaram a ilustrar a performance dos modelos e a identificar poss√≠veis √°reas de melhoria. Analisamos os resultados no contexto dos objetivos do estudo, discutindo as limita√ß√µes e pontos fortes de cada modelo. Esta etapa foi crucial para entender as limita√ß√µes dos dados e dos modelos utilizados, al√©m de apontar dire√ß√µes para futuras melhorias e ajustes.

Foi muito engrandecedor conseguir avan√ßar, aprender e concluir essa pesquisa. Espero que quem veja esse trabalho consiga aproveitar algo. Agrade√ßemos √† professora Luciana pelo suporte.

# V√≠deo Completo

O v√≠deo contem toda a apresenta√ß√£o e explica√ß√£o dos experimentos realizados. 

Link: 
